{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa769c1-5418-4151-ab0b-2808082563eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538f5b29-aa22-466b-bb04-baa0b8c89392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting:\n",
    "# Model learns training data too well, capturing noise and random fluctuations in the data.\n",
    "# Consequences: Poor generalization to new data, high variance, and complex model.\n",
    "# Mitigation: Reduce model complexity, use more data, regularization.\n",
    "\n",
    "#Underfitting:\n",
    "# Model is too simple to capture data patterns.\n",
    "# Consequences: Poor performance, high bias.\n",
    "# Mitigation: Increase model complexity, collect more data, fine-tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8f543d-69a8-4a9d-ac08-0d6f27e0c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2.\n",
    "\n",
    "# To reduce overfitting:\n",
    "\n",
    "# Use cross-validation for robust model evaluation.\n",
    "# Apply regularization (L1/L2).\n",
    "# Carefully select features.\n",
    "# Engineer meaningful features.\n",
    "# Choose simpler models.\n",
    "# Get more data.\n",
    "# Implement early stopping.\n",
    "# Use ensemble methods.\n",
    "# Apply dropout in neural networks.\n",
    "# Augment training data.\n",
    "# Simplify model architectures.\n",
    "# Reserve a validation set for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254f2436-046e-43c2-8db7-4e2a5c7eec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79cf51c8-b2b6-4a67-ac49-8dfa292491ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underfitting occurs when a model is too simplistic.\n",
    "# It can result from insufficient model complexity.\n",
    "# Small training datasets can lead to underfitting.\n",
    "# Excessive regularization can cause underfitting.\n",
    "# Ignoring important features or patterns leads to underfit models.\n",
    "# Choosing a model with fewer parameters than needed is another cause.\n",
    "# Ignoring the data distribution or not matching the problem's complexity contributes to underfitting.\n",
    "# Incorrectly setting hyperparameters, like an extremely small learning rate, can result in underfitting.\n",
    "# To mitigate underfitting, increase model complexity, gather more data, improve feature engineering, or choose a more suitable algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f308c667-b75d-48fd-ab17-9a57d07d80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4.\n",
    "\n",
    "# Bias: Measures how well a model approximates the true relationshoip in data.\n",
    "# Variance: Measures the model's sensitivity to small changes in the training data.\n",
    "# Tradeoff: Balancing bias and variance is crucial for model performance.\n",
    "# High Bias (Underfitting): Model is too simplistic, doesn't capture data patterns, performs poorly.\n",
    "# High Variance (Overfitting): Model is too complex, fits training data too closely, performs poorly on new data.\n",
    "# Finding Balance: Optimal models have moderate bias and variance.\n",
    "# Regularization: Technique to control variance and prevent overfitting.\n",
    "# Goal: Achieve a model that generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a5ad30e-677d-4aca-8405-0ac4cdbd1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.\n",
    "\n",
    "# Detecting Overfitting:\n",
    "# Validation Set: Use a separate validation set to check for declining performance.\n",
    "# Learning Curves: Visualize the training and validation error over time.\n",
    "# Cross-Validation: Split data into multiple subsets for training and validation.\n",
    "# Regularization: Apply techniques like L1 or L2 regularization to penalize complex models.\n",
    "# Feature Selection: Removing irrelevant or redundant features can reduce overfitting.\n",
    "\n",
    "# Detecting Underfitting:\n",
    "\n",
    "# Learning Curves: Check if both training and validation error remain high.\n",
    "# Model Complexity: If the model is too simple, it may underfit; try a more complex model.\n",
    "# Feature Engineering: Adding relevant features can help the model capture patterns.\n",
    "# Ensemble Methods: Combine multiple simple models to form a stronger learner.\n",
    "\n",
    "#Determination:\n",
    "\n",
    "# Overfitting: Training error is low, but validation error is high.\n",
    "# Underfitting: Both training and validation errors are high, and the model struggles to fit the data.\n",
    "# Balance: Achieving a good trade-off between bias and variance is the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c84a13-0e88-4a4f-9e8b-1aaa8aa42d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6.\n",
    "\n",
    "# Bias:\n",
    "\n",
    "# Measures how far model predictions are from the actual values.\n",
    "# High bias leads to underfitting.\n",
    "# Low complexity models.\n",
    "# Both training and validation errors are high but close.\n",
    "# E.g. Linear regression with insufficient features.\n",
    "# E.g. Constant prediction for all inputs.\n",
    "\n",
    "# Variance:\n",
    "\n",
    "# Measures model's sensitivity to training data noise.\n",
    "# High variance leads to overfitting.\n",
    "# High complexity models.\n",
    "# Training error is low, validation error is high.\n",
    "# E.g. Decision trees with deep branches.\n",
    "# E.g. High-degree polynomial regression.\n",
    "\n",
    "# Comparison:\n",
    "\n",
    "# Trade-off: Reducing one often increases the other.\n",
    "# Performance: High bias performs poorly everywhere, high variance performs well on training but poorly on validation.\n",
    "# Fixing: Increase complexity, add features for bias, reduce complexity, increase data, or use regularization for variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "355825f8-e18a-4a75-b211-472d03665b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7.\n",
    "\n",
    "# Regularization prevents overfitting by adding a penalty to the loss function.\n",
    "\n",
    "# Common techniques include L1 (Lasso) and L2 (Ridge) regularization, which control the complexity of models by encouraging smaller or sparser coefficients.\n",
    "\n",
    "# Other methods like dropout and early stopping are also used to combat overfitting in specific contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3744a426-31d7-4ad4-9431-1013983132ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583fd5b7-58f6-4510-88c0-fe1690cba26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
